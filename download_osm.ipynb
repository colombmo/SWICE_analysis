{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data using overpass API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import overpy\n",
    "import json\n",
    "from helpers.ways_converter import ways2poly\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = overpy.Overpass() \n",
    "# Use swiss instance of the API\n",
    "api.default_url=\"https://overpass.osm.ch/api/interpreter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = api.query(\"\"\"\n",
    "            [out:json];\n",
    "            area[\"ISO3166-1\"=\"CH\"]->.searchArea;\n",
    "            (\n",
    "            // Close to a train track?\n",
    "            way[\"railway\"=\"rail\"][\"usage\"=\"main\"](area.searchArea);\n",
    "            way[\"railway\"=\"rail\"][\"usage\"=\"branch\"](area.searchArea);\n",
    "            \n",
    "            // Close to metro rails?\n",
    "            way[\"railway\"=\"subway\"](area.searchArea);\n",
    "            way[\"railway\"=\"subway_entrance\"](area.searchArea);\n",
    "            \n",
    "            // Consider other \"alternative\" rail types, like light rail and funicular\n",
    "            way[\"railway\"=\"light_rail\"](area.searchArea);\n",
    "            way[\"railway\"=\"funicular\"](area.searchArea);\n",
    "            way[\"railway\"=\"narrow_gauge\"](area.searchArea);\n",
    "            way[\"railway\"=\"monorail\"](area.searchArea);\n",
    "            \n",
    "            // Just for fun: miniature rail\n",
    "            way[\"railway\"=\"miniature\"](area.searchArea);\n",
    "            \n",
    "            // Consider cable cars etc as \"trains\" as well\n",
    "            way[\"aerialway\"](area.searchArea);\n",
    "                    \n",
    "            );\n",
    "            out body;\n",
    "            >;\n",
    "            out skel qt;\n",
    "                    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tram = api.query(\"\"\"\n",
    "            [out:json];\n",
    "            area[\"ISO3166-1\"=\"CH\"]->.searchArea;\n",
    "            (\n",
    "            // Close to tram rails?\n",
    "            way[\"railway\"=\"tram\"](area.searchArea);\n",
    "            rel[\"route\"=\"tram\"](area.searchArea);\n",
    "            );\n",
    "            out body;\n",
    "            >;\n",
    "            out skel qt;\n",
    "                    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all swiss cantons in ISO 3166-2 format\n",
    "# https://en.wikipedia.org/wiki/ISO_3166-2:CH\n",
    "cantons = [\"AG\", \"AI\", \"AR\", \"BE\", \"BL\", \"BS\", \"FR\", \"GE\", \"GL\", \"GR\", \"JU\", \"LU\", \"NE\", \"NW\", \"OW\", \"SG\", \"SH\", \"SO\", \"SZ\", \"TG\", \"TI\", \"UR\", \"VD\", \"VS\", \"ZG\", \"ZH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished AG\n",
      "Finished AI\n",
      "Finished AR\n",
      "Finished BE\n",
      "Finished BL\n",
      "Finished BS\n",
      "Finished FR\n",
      "Finished GE\n",
      "Finished GL\n",
      "Finished GR\n",
      "Finished JU\n",
      "Finished LU\n",
      "Finished NE\n",
      "Finished NW\n",
      "Finished OW\n",
      "Finished SG\n",
      "Finished SH\n",
      "Finished SO\n",
      "Finished SZ\n",
      "Finished TG\n",
      "Finished TI\n",
      "Finished UR\n",
      "Finished VD\n",
      "Finished VS\n",
      "Finished ZG\n",
      "Finished ZH\n"
     ]
    }
   ],
   "source": [
    "buses_list = []\n",
    "\n",
    "for canton in cantons:\n",
    "        res = api.query(f\"\"\"\n",
    "            [out:json];\n",
    "            area[\"ISO3166-2\"=\"CH-{canton}\"]->.searchArea;\n",
    "            (\n",
    "                    \n",
    "            // Close to bus line?\n",
    "            rel[\"route\"=\"trolleybus\"](area.searchArea);\n",
    "            rel[\"route\"=\"bus\"](area.searchArea);\n",
    "            );\n",
    "            out body;\n",
    "            >;\n",
    "            out skel qt;\n",
    "                    \"\"\")\n",
    "        buses_list.append(res)\n",
    "        print(f\"Finished {canton}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge buses into one object\n",
    "results_buses = overpy.Result()\n",
    "\n",
    "for res in buses_list:\n",
    "    results_buses.expand(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lakes = api.query(\"\"\"\n",
    "        [out:json];\n",
    "        area[\"ISO3166-1\"=\"CH\"]->.searchArea;\n",
    "        (\n",
    "                \n",
    "        // Lakes\n",
    "        relation[\"water\"=\"lake\"](area.searchArea);\n",
    "        relation[\"water\"=\"reservoir\"](area.searchArea);\n",
    "        );\n",
    "        out body;\n",
    "        >;\n",
    "        out skel qt;\n",
    "                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = False\n",
    "# build polygons from the lakes relations\n",
    "lake_boundaries = {}\n",
    "for lake in results_lakes.relations:\n",
    "    k = lake.id\n",
    "    # Convert to list of ways\n",
    "    ways = [way for way in results_lakes.ways if way.id in [m.ref for m in lake.members]]\n",
    "\n",
    "    polys, incmp = ways2poly(ways)\n",
    "    lake_boundaries[k] = {'polygons': polys, 'incomplete': incmp}\n",
    "\n",
    "    \n",
    "    if len(polys) > 0 and len(incmp) == 0:\n",
    "        outcome = 'OK'\n",
    "    else:\n",
    "        outcome = 'ERROR'\n",
    "\n",
    "    if log:\n",
    "        print(\"{}: {:>2} polygons, {:>2} incomplete ({})\".format(\n",
    "            k, len(polys), len(incmp), outcome))\n",
    "\n",
    "    # I only care about complete polygons, but you could process incomplete\n",
    "    # ones as (Multi)LineString if needed\n",
    "    if outcome == 'OK':\n",
    "        lake_boundaries[k]['shape'] = MultiPolygon(\n",
    "            [Polygon([(n.lon, n.lat) for n in p]) for p in polys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the geojson of switzerland\n",
    "ch = gpd.read_file(\"data/switzerland.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean results_train to keep only the points in ch, and then remove the ways with less than 2 points\n",
    "train_points = []\n",
    "for way in results_train.ways:\n",
    "    points = [(node.lon, node.lat) for node in way.nodes if ch.contains(Point(float(node.lon), float(node.lat))).values[0]]\n",
    "    if len(points) > 1:\n",
    "        train_points.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean results_tram to keep only the points in ch, and then remove the ways with less than 2 points\n",
    "tram_points = []\n",
    "for way in results_tram.ways:\n",
    "    points = [(node.lon, node.lat) for node in way.nodes if ch.contains(Point(float(node.lon), float(node.lat))).values[0]]\n",
    "    if len(points) > 1:\n",
    "        tram_points.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean results_bus to keep only the points in ch, and then remove the ways with less than 2 points\n",
    "bus_points = []\n",
    "for way in results_buses.ways:\n",
    "    points = [(node.lon, node.lat) for node in way.nodes if ch.contains(Point(float(node.lon), float(node.lat))).values[0]]\n",
    "    if len(points) > 1:\n",
    "        bus_points.append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build geojson object from the results\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "# Add train lines to geojson, but keep only the nodes inside switzerland\n",
    "for way in train_points:\n",
    "    geojson[\"features\"].append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"LineString\",\n",
    "            \"coordinates\": [[float(node[0]), float(node[1])] for node in way]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"type\": \"train\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "for way in tram_points:\n",
    "    geojson[\"features\"].append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"LineString\",\n",
    "            \"coordinates\": [[float(node[0]), float(node[1])] for node in way]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"type\": \"tram\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "for way in bus_points:\n",
    "    geojson[\"features\"].append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"LineString\",\n",
    "            \"coordinates\": [[float(node[0]), float(node[1])] for node in way]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"type\": \"bus\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Append lakes to geojson as multipolygons\n",
    "for k, v in lake_boundaries.items():\n",
    "    geojson['features'].append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Polygon\",\n",
    "            \"coordinates\": [[(float(n.lon), float(n.lat)) for n in poly] for poly in v['polygons']]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"type\": \"lake\",\n",
    "        }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results/swiss_map_mot_type.geojson\", \"w\") as f:\n",
    "    json.dump(geojson, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the file\n",
    "\n",
    "# 1. Reduce precision of coordinates, keep only 5 after the comma\n",
    "geojson[\"features\"] = [\n",
    "    {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": feature[\"geometry\"][\"type\"],\n",
    "            \"coordinates\": [[round(x, 5) if isinstance(x, float) else (round(float(x[0]), 5), round(float(x[1]), 5)) \n",
    "                             for x in coord] for coord in feature[\"geometry\"][\"coordinates\"]]\n",
    "        },\n",
    "        \"properties\": feature[\"properties\"]\n",
    "    }\n",
    "    for feature in geojson[\"features\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to compare size\n",
    "with open(\"./results/swiss_map_mot_type_compressed.geojson\", \"w\") as f:\n",
    "    json.dump(geojson, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in geopandas\n",
    "gdf = gpd.read_file(\"./results/swiss_map_mot_type_compressed.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the geometries\n",
    "gdf[\"geometry\"] = gdf[\"geometry\"].simplify(tolerance=0.0001) # 0.0001 degrees tolerance, it's about 11.1 m!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to geojson again\n",
    "gdf.to_file(\"./results/swiss_map_mot_type_simplified.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload as json object\n",
    "with open(\"./results/swiss_map_mot_type_simplified.geojson\", \"r\") as f:\n",
    "    geojson_simplified = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform geojson_simplified to dictionary of LineStrings and Polygons\n",
    "trains = []\n",
    "trams = []\n",
    "buses = []\n",
    "lakes = []\n",
    "\n",
    "for feature in geojson_simplified[\"features\"]:\n",
    "    if feature[\"properties\"][\"type\"] == \"train\":\n",
    "        trains.append(feature[\"geometry\"][\"coordinates\"])\n",
    "    elif feature[\"properties\"][\"type\"] == \"tram\":\n",
    "        trams.append(feature[\"geometry\"][\"coordinates\"])\n",
    "    elif feature[\"properties\"][\"type\"] == \"bus\":\n",
    "        buses.append(feature[\"geometry\"][\"coordinates\"])\n",
    "    elif feature[\"properties\"][\"type\"] == \"lake\":\n",
    "        lakes.append(feature[\"geometry\"][\"coordinates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Svae all these as json, with less information than the geojson\n",
    "with open(\"./results/swiss_mots_small.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"trains\": trains,\n",
    "        \"trams\": trams,\n",
    "        \"buses\": buses,\n",
    "        \"lakes\": lakes\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to the format {\"trains\": [{\"p\": [\"{x: 1, y: 2}\", \"{x: 2, y: 3}\", ...]}, ...]}\n",
    "with open(\"./results/swiss_mots_small.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as strings, which can then be directly put in the database as strings (without quotes, so need to use json lenient parser)\n",
    "data = {\n",
    "    \"trains\": [{\"p\": [{\"x\": x, \"y\": y} for x, y in line]} for line in data[\"trains\"]],\n",
    "    \"trams\": [{\"p\": [{\"x\": x, \"y\": y} for x, y in line]} for line in data[\"trams\"]],\n",
    "    \"buses\": [{\"p\": [{\"x\": x, \"y\": y} for x, y in line]} for line in data[\"buses\"]],\n",
    "    \"lakes\": [{\"r\": [{\"p\": [{\"x\": x, \"y\": y} for x, y in ring]} for ring in poly]} for poly in data[\"lakes\"]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as json\n",
    "with open(\"./results/swiss_mots.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get minX, minY, maxX, maxY from each element inside a list [{\"x\"\": 1, \"y\": 2}, ...]\n",
    "def get_bbox(points):\n",
    "    min_x = min([point[\"x\"] for point in points])\n",
    "    min_y = min([point[\"y\"] for point in points])\n",
    "    max_x = max([point[\"x\"] for point in points])\n",
    "    max_y = max([point[\"y\"] for point in points])\n",
    "    return str(min_x)+\",\"+str(min_y)+\",\"+str(max_x)+\",\"+str(max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the names of the vehicles in the json file and in the SQL database\n",
    "vehicles = {\n",
    "    \"trains\": \"TRAIN\",\n",
    "    \"trams\": \"TRAM\",\n",
    "    \"buses\": \"BUS\",\n",
    "    \"lakes\": \"LAKE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400 # Create batches of 400 queries each -- There is a limit of 500 unions, but we take 400 just to be on the safe side\n",
    "query = \"\"\n",
    "# Delete all the data from the spatialdata table, before inserting the new data\n",
    "query+= f\"\"\"\n",
    "DELETE FROM SpatialData;\n",
    "\"\"\"\n",
    "\n",
    "for k,v in vehicles.items():\n",
    "    # Transform this to SQL queries to insert in the database, with VEHICLE, GEOMETRY in json format, and the bounding box of each element\n",
    "    # so minX, minY, maxX, maxY, by getting the id of the vehicle by its name first (SELECT id FROM Vehicles WHERE name = \"TRAIN\";) and\n",
    "    # saving that as a variable\n",
    "\n",
    "    tq = f\"\"\"\n",
    "CREATE TEMPORARY TABLE temp_{k}_id AS\n",
    "SELECT id FROM OSMVehicles WHERE name = '{v}' LIMIT 1;\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a query for each train line -- Using this type of query, in batches, \n",
    "    # accelerates the insertion more than 10x (from 3.5s to 0.3s)\n",
    "    if k == \"lakes\":\n",
    "        t = [\"SELECT tv.id,'{}',{} FROM temp_{}_id tv\".format(str(poly['r']).replace('\\'', '\\\"'), get_bbox(poly['r'][0]['p']), k) for poly in data[k]]\n",
    "    else:\n",
    "        t = [\"SELECT tv.id,'{}',{} FROM temp_{}_id tv\".format(str(way['p']).replace('\\'', '\\\"'), get_bbox(way['p']), k) for way in data[k]]\n",
    "\n",
    "    # Divide data in batches and create a query for each batch\n",
    "    batches = [t[i:i+batch_size] for i in range(0, len(t), batch_size)]\n",
    "    \n",
    "    # Build a query for each batch\n",
    "    queries = [\"INSERT INTO SpatialData (vehicle, geometry, minX, minY, maxX, maxY)\" + \" UNION ALL \".join(b)+\";\" for b in batches]\n",
    "\n",
    "    tq += \" \".join(queries)\n",
    "\n",
    "    query += tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file, named as year_month_osm_db.sql\n",
    "import datetime\n",
    "with open(f\"./results/{datetime.datetime.now().strftime('%Y_%m')}_osm_db.sql\", \"w\") as f:\n",
    "    f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to update osm_db\n",
    "\n",
    "1. Run this script, which generates a file in results/ named `{year}_{month}_osm_db.sql`. This file contains sql calls to populate the content of the local database (in the app) with all the railways, tram lines, buses, and lakes of Switzerland.\n",
    "2. Test the generated file with `test_sqlite.ipynb`\n",
    "3. Once passed the test, go to the source code of `swice_server`and:\n",
    "    - Copy the generated `{year}_{month}_osm_db.sql` file in the folder `app/osm_data``\n",
    "    - Open the `app/api/views.py`file and edit the `osm_get_latest_version` function to return the string `\"{year}_{month}\"`corresponding the the just uploaded file\n",
    "    - Commit and push the changes\n",
    "    - Run the github action `Publish to the production server`in the `swice_app`repository\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osmnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
