{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the geohashes corresponding to Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geohash\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import os\n",
    "import csv\n",
    "import helpers.sizeof as sizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 8 # Let's do this at a very high level to start filtering out all we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the borders of switzerland\n",
    "ch = gpd.read_file(\"./data/switzerland.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load or generate a list of points inside the boundaries of switzerland\n",
    "def get_swiss_geohashes(\n",
    "        load = True,\n",
    "        from_previous_level = False,\n",
    "        gran = 1000, # The granularity of the grid\n",
    "        level = 7, # The level of the geohashes\n",
    "        filename = \"geohashes_ch\"):\n",
    "    if from_previous_level and level > 1 and os.path.exists(f'./data/{filename}_{level-1}.csv'):\n",
    "        print(f\"Loading geohashes from previous level ({level-1})\")\n",
    "        \n",
    "        with open(f'./data/{filename}_{level-1}.csv', 'r') as f:\n",
    "            read = csv.reader(f)\n",
    "            geohashes = list(read)\n",
    "\n",
    "        # Get rid of nested lists\n",
    "        geohashes = [gh[0] for gh in geohashes]\n",
    "\n",
    "        # List of all possible characters in a geohash\n",
    "        chars = \"0123456789bcdefghjkmnpqrstuvwxyz\"\n",
    "\n",
    "        # Generate the next level of geohashes\n",
    "        new_geohashes = []\n",
    "        for gh in geohashes:\n",
    "            for char in chars:\n",
    "                new_geohashes.append(gh + char)\n",
    "\n",
    "        # Save the new geohashes to a csv file\n",
    "        ng = [[gh] for gh in new_geohashes]\n",
    "\n",
    "        # Save the geohashes to a csv file\n",
    "        with open(f'./data/{filename}_{level}.csv', 'w') as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerows(ng)\n",
    "\n",
    "        geohashes = [gh[0] for gh in ng]\n",
    "\n",
    "        print(f\"Loaded {len(geohashes)} geohashes\")\n",
    "\n",
    "        return new_geohashes\n",
    "    \n",
    "    elif load and os.path.exists(f'./data/{filename}_{level}.csv'):\n",
    "        print(\"Loading geohashes from file\")\n",
    "        \n",
    "        with open(f'./data/{filename}_{level}.csv', 'r') as f:\n",
    "            read = csv.reader(f)\n",
    "            geohashes = list(read)\n",
    "\n",
    "        # Get rid of nested lists\n",
    "        geohashes = [gh[0] for gh in geohashes]\n",
    "\n",
    "        print(f\"Loaded {len(geohashes)} geohashes\")\n",
    "        \n",
    "        return geohashes\n",
    "    else:\n",
    "        print(\"Generating geohashes\")\n",
    "        # Define the bounding box for Switzerland (from https://giswiki.hsr.ch/Bounding_Box)\n",
    "        min_lat, max_lat = 45.6755, 47.9163\n",
    "        min_lon, max_lon = 5.7349, 10.6677\n",
    "\n",
    "        # Create a list of points inside the bounding box (TODO: Do this with some range function)\n",
    "        # Create a grid of latitudes and longitudes\n",
    "        latitudes = np.arange(int(min_lat*gran), int(max_lat*gran)+1) / gran\n",
    "        longitudes = np.arange(int(min_lon*gran), int(max_lon*gran)+1) / gran\n",
    "\n",
    "        # Create a meshgrid of latitudes and longitudes\n",
    "        lon_mesh, lat_mesh = np.meshgrid(longitudes, latitudes)\n",
    "\n",
    "        # Create a flattened array of points\n",
    "        points_t = np.column_stack((lon_mesh.ravel(), lat_mesh.ravel()))\n",
    "\n",
    "        # Convert the flattened array to a list of Shapely Points\n",
    "        points_t = [Point(lon, lat) for lon, lat in points_t]\n",
    "\n",
    "        points = gpd.GeoDataFrame(geometry=points_t, crs='EPSG:4326')\n",
    "\n",
    "        # From points, keep only those inside the borders of Switzerland\n",
    "        filtered = gpd.sjoin(points, ch, predicate='intersects')\n",
    "        filtered.drop(columns=['index_right'], inplace=True)\n",
    "        filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Transform the retrieved points to geohashes\n",
    "        geohashes = filtered.geometry.apply(lambda x: geohash.encode(x.y, x.x, precision=level))\n",
    "\n",
    "        print(\"Before removing duplicates:\", len(geohashes))\n",
    "\n",
    "        # Get unique geohashes\n",
    "        geohashes = list(set(geohashes))\n",
    "\n",
    "        print(\"After removing duplicates:\", len(geohashes))\n",
    "\n",
    "        geohashes = [[gh] for gh in geohashes]\n",
    "\n",
    "        # Save the geohashes to a csv file\n",
    "        with open(f'./data/{filename}_{level}.csv', 'w') as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerows(geohashes)\n",
    "\n",
    "        geohashes = [gh[0] for gh in geohashes]\n",
    "\n",
    "        return geohashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading geohashes from previous level (7)\n",
      "Loaded 9806176 geohashes\n"
     ]
    }
   ],
   "source": [
    "geohashes = get_swiss_geohashes(load=True, gran = 100, level=level, from_previous_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     geohashes: 75.5 MiB\n",
      "                         rects: 65.2 MiB\n",
      "                          mots: 39.4 MiB\n",
      "           geohashes_filtered1: 38.3 MiB\n",
      "            geohashes_filtered: 36.6 MiB\n",
      "                rects_filtered: 23.4 MiB\n",
      "                           _83: 18.8 MiB\n",
      "                    geometries:  8.1 MiB\n",
      "                          _241:  3.6 MiB\n",
      "                           _62:  2.0 MiB\n"
     ]
    }
   ],
   "source": [
    "sizeof.variables(locals().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the geojson with the means of transport of switzerland\n",
    "mots = gpd.read_file(\"./results/swiss_map_mot_type.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geohash_to_rect(gh):\n",
    "    bbox = geohash.bbox(gh)\n",
    "    return Polygon(\n",
    "        [(bbox['w'], bbox['s']), (bbox['w'], bbox['n']), (bbox['e'], bbox['n']), (bbox['e'], bbox['s'])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all geohashes to rectangles\n",
    "geometries = [geohash_to_rect(gh) for gh in geohashes]\n",
    "\n",
    "# Create a GeoDataFrame directly from the list of geometries\n",
    "rects = gpd.GeoDataFrame(geometry=geometries, crs='EPSG:4326')\n",
    "\n",
    "rects['geohash'] = geohashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9806176"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only geohashes partially inside the borders of Switzerland\n",
    "rects = gpd.sjoin(rects, ch, predicate='intersects')\n",
    "rects.drop(columns=['index_right'], inplace=True)\n",
    "rects.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9779294"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the rectangles that intersect with at least one of the means of transport, including lakes\n",
    "geohashes_filtered = gpd.sjoin(rects, mots, predicate='intersects')\n",
    "geohashes_filtered.drop(columns=['index_right'], inplace=True)\n",
    "geohashes_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(x):\n",
    "    return {k: v for d in x.dropna() for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the strings of the means of transport, removing duplicates\n",
    "def merge_strings(x):\n",
    "    return ','.join(x.dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the geohashes with the same code, putting together all the elements in the tags column\n",
    "geohashes_filtered = geohashes_filtered.groupby('geohash').agg({'type': merge_strings}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 9806176\n",
      "After: 4111093\n",
      "Difference: 5695083\n"
     ]
    }
   ],
   "source": [
    "# Show the reduction in geohashes\n",
    "print(\"Before:\", len(geohashes))\n",
    "print(\"After:\", len(geohashes_filtered))\n",
    "print(\"Difference:\", len(geohashes) - len(geohashes_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the geohashes to a csv file\n",
    "geohashes_filtered['geohash'].to_csv(f'./data/geohashes_ch_{level}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From rects, keep only the ones with a geohash in geohashes_filtered\n",
    "rects_filtered = rects[rects['geohash'].isin(geohashes_filtered['geohash'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "rects_filtered.plot(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osmnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
