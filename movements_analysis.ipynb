{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movement data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the movement data collected during the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from branca.colormap import linear\n",
    "from geolib import geohash as geolib\n",
    "import json\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_geohash</th>\n",
       "      <th>end_geohash</th>\n",
       "      <th>distance(m)</th>\n",
       "      <th>mean_of_transport</th>\n",
       "      <th>is_power_saving</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119928XAX</td>\n",
       "      <td>2023-11-22 15:07:41+00:00</td>\n",
       "      <td>2023-11-22 15:29:35+00:00</td>\n",
       "      <td>u0m468</td>\n",
       "      <td>u0m714</td>\n",
       "      <td>53753</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119928XAX</td>\n",
       "      <td>2023-11-22 15:36:51+00:00</td>\n",
       "      <td>2023-11-22 15:49:36+00:00</td>\n",
       "      <td>u0m714</td>\n",
       "      <td>u0m70f</td>\n",
       "      <td>1365</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219935XE1</td>\n",
       "      <td>2023-11-12 19:26:43+00:00</td>\n",
       "      <td>2023-11-12 19:44:21+00:00</td>\n",
       "      <td>u0qh02</td>\n",
       "      <td>u0mgtj</td>\n",
       "      <td>22038</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219935XE1</td>\n",
       "      <td>2023-11-12 19:49:14+00:00</td>\n",
       "      <td>2023-11-12 19:54:59+00:00</td>\n",
       "      <td>u0mgtj</td>\n",
       "      <td>u0mgth</td>\n",
       "      <td>290</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219935XE1</td>\n",
       "      <td>2023-11-12 20:01:35+00:00</td>\n",
       "      <td>2023-11-12 21:01:40+00:00</td>\n",
       "      <td>u0mgth</td>\n",
       "      <td>u0m714</td>\n",
       "      <td>103394</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2198211RX</td>\n",
       "      <td>2023-12-05 07:46:58+00:00</td>\n",
       "      <td>2023-12-05 08:01:57+00:00</td>\n",
       "      <td>u0m44w</td>\n",
       "      <td>u0m44y</td>\n",
       "      <td>1342</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2198211RX</td>\n",
       "      <td>2023-12-04 21:33:35+00:00</td>\n",
       "      <td>2023-12-04 21:36:53+00:00</td>\n",
       "      <td>u0kcvw</td>\n",
       "      <td>u0kcvm</td>\n",
       "      <td>1347</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2198211RX</td>\n",
       "      <td>2023-12-05 06:13:44+00:00</td>\n",
       "      <td>2023-12-05 06:16:56+00:00</td>\n",
       "      <td>u0kcvw</td>\n",
       "      <td>u0kcvm</td>\n",
       "      <td>1290</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2198211RX</td>\n",
       "      <td>2023-12-05 08:02:11+00:00</td>\n",
       "      <td>2023-12-05 08:06:00+00:00</td>\n",
       "      <td>u0m44y</td>\n",
       "      <td>u0m44y</td>\n",
       "      <td>186</td>\n",
       "      <td>ON_BICYCLE</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2198211RX</td>\n",
       "      <td>2023-12-05 11:15:14+00:00</td>\n",
       "      <td>2023-12-05 11:20:56+00:00</td>\n",
       "      <td>u0m44y</td>\n",
       "      <td>u0m44y</td>\n",
       "      <td>338</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant_id                 start_time                   end_time  \\\n",
       "0        119928XAX  2023-11-22 15:07:41+00:00  2023-11-22 15:29:35+00:00   \n",
       "1        119928XAX  2023-11-22 15:36:51+00:00  2023-11-22 15:49:36+00:00   \n",
       "2        219935XE1  2023-11-12 19:26:43+00:00  2023-11-12 19:44:21+00:00   \n",
       "3        219935XE1  2023-11-12 19:49:14+00:00  2023-11-12 19:54:59+00:00   \n",
       "4        219935XE1  2023-11-12 20:01:35+00:00  2023-11-12 21:01:40+00:00   \n",
       "..             ...                        ...                        ...   \n",
       "431      2198211RX  2023-12-05 07:46:58+00:00  2023-12-05 08:01:57+00:00   \n",
       "432      2198211RX  2023-12-04 21:33:35+00:00  2023-12-04 21:36:53+00:00   \n",
       "433      2198211RX  2023-12-05 06:13:44+00:00  2023-12-05 06:16:56+00:00   \n",
       "434      2198211RX  2023-12-05 08:02:11+00:00  2023-12-05 08:06:00+00:00   \n",
       "435      2198211RX  2023-12-05 11:15:14+00:00  2023-12-05 11:20:56+00:00   \n",
       "\n",
       "    start_geohash end_geohash distance(m) mean_of_transport is_power_saving  \\\n",
       "0          u0m468      u0m714       53753             TRAIN           False   \n",
       "1          u0m714      u0m70f        1365           WALKING           False   \n",
       "2          u0qh02      u0mgtj       22038             TRAIN           False   \n",
       "3          u0mgtj      u0mgth         290           WALKING           False   \n",
       "4          u0mgth      u0m714      103394             TRAIN           False   \n",
       "..            ...         ...         ...               ...             ...   \n",
       "431        u0m44w      u0m44y        1342           WALKING           False   \n",
       "432        u0kcvw      u0kcvm        1347           WALKING           False   \n",
       "433        u0kcvw      u0kcvm        1290           WALKING           False   \n",
       "434        u0m44y      u0m44y         186        ON_BICYCLE           False   \n",
       "435        u0m44y      u0m44y         338           WALKING           False   \n",
       "\n",
       "    geometry  \n",
       "0       None  \n",
       "1       None  \n",
       "2       None  \n",
       "3       None  \n",
       "4       None  \n",
       "..       ...  \n",
       "431     None  \n",
       "432     None  \n",
       "433     None  \n",
       "434     None  \n",
       "435     None  \n",
       "\n",
       "[436 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read the data from the csv\n",
    "df = gpd.read_file('data/Test_movements.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant_id\n",
       "2198211RX     145\n",
       "219935XE1     140\n",
       "2197410XTX     57\n",
       "119928XAX      49\n",
       "119963XR1      27\n",
       "219613XI1      11\n",
       "219827XRX       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get a list of all the unique participants in df, including the number of occurrences of each participant\n",
    "participants = df['participant_id'].value_counts()\n",
    "participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a heatmap of the locations visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract from df a list of all start_geohashes and end_geohashes\n",
    "geohashes = list(df['start_geohash']) + list(df['end_geohash'])\n",
    "len(geohashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want, we can remove some characters from the end of each geohash to reduce the precision\n",
    "geohashes = [geohash[:-1] for geohash in geohashes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of geohashes to a dataframe\n",
    "geohashes_df = gpd.GeoDataFrame(geohashes, columns=['geohash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the list of geohashes to a geoJSON object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â Convert geohashes to a heatmap in geojson format\n",
    "def geohashes_to_heatmap(df):\n",
    "    # Get the distinct geohashes and their counts from the dataframe\n",
    "    geohashes = df['geohash'].value_counts()\n",
    "\n",
    "    print(geohashes)\n",
    "\n",
    "    # Get the maximum count of any geohash\n",
    "    max_count = math.log(geohashes.max())\n",
    "\n",
    "    # Convert the geohashes to a list of lists, each containing the geohash and its count\n",
    "    geohashes = [[geohash, count] for geohash, count in zip(geohashes.index, geohashes)]\n",
    "    \n",
    "    # Create a color scale for the heatmap\n",
    "    color_scale = linear.RdYlBu_10.scale(1, max_count)\n",
    "\n",
    "    # Convert geohashes to features for geoJSON\n",
    "    features = []\n",
    "\n",
    "    for geohash in geohashes:\n",
    "        # Get the bounds of the geohash\n",
    "        bounds = geolib.bounds(geohash[0])\n",
    "        color = color_scale(math.log(geohash[1]))\n",
    "\n",
    "        # Create a feature for the geohash\n",
    "        features.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"id\": geohash[0],\n",
    "                \"fillColor\": color,\n",
    "                \"fillOpacity\": 0.6,\n",
    "                \"stroke\": False\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Polygon\",\n",
    "                \"coordinates\": [[\n",
    "                    [bounds.sw.lon, bounds.sw.lat],\n",
    "                    [bounds.sw.lon, bounds.ne.lat],\n",
    "                    [bounds.ne.lon, bounds.ne.lat],\n",
    "                    [bounds.ne.lon, bounds.sw.lat],\n",
    "                    [bounds.sw.lon, bounds.sw.lat]\n",
    "                ]]\n",
    "            },\n",
    "        })\n",
    "\n",
    "    # Convert the geohashes to a heatmap in geojson format\n",
    "    return {\n",
    "        \"type\" : \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geohash\n",
      "u0m44    142\n",
      "u0kcu    116\n",
      "u0m70    109\n",
      "u0m71     77\n",
      "u0m46     55\n",
      "        ... \n",
      "u0m4e      1\n",
      "u0kbg      1\n",
      "u0q1e      1\n",
      "u0q1u      1\n",
      "u0m6j      1\n",
      "Name: count, Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the geohashes to a heatmap in geojson format\n",
    "heatmap = geohashes_to_heatmap(geohashes_df)\n",
    "\n",
    "# Save GeoJSON with double quotes\n",
    "with open('results/heatmap.geojson', 'w') as f:\n",
    "    json.dump(heatmap, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as a heatmap using Folium\n",
    "# Create a folium map centered at an initial location\n",
    "m = folium.Map(location=[46.9446011, 7.4143311], zoom_start=5)\n",
    "\n",
    "# Define a style function to set the color of the polygon\n",
    "def style_function(feature):\n",
    "    return {\n",
    "        'fillColor': feature[\"properties\"][\"fillColor\"],  # Change this to the desired color\n",
    "        'stroke': feature[\"properties\"][\"stroke\"],\n",
    "        'fillOpacity': feature[\"properties\"][\"fillOpacity\"],\n",
    "    }\n",
    "\n",
    "# Add GeoJSON data to the map with the style function\n",
    "folium.GeoJson(\n",
    "    heatmap,\n",
    "    name='Polygon Layer',\n",
    "    style_function=style_function,\n",
    ").add_to(m)\n",
    "\n",
    "# Add Layer Control to the map\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save or display the map\n",
    "m.save(\"folium_map_with_colored_polygon.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osmnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
