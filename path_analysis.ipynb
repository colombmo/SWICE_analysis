{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test visualizing paths using geohashes with decreasing precision the further they are from the defined center of an area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from branca.colormap import linear\n",
    "from geolib import geohash as geolib\n",
    "import geopy.distance\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = (46.79381345553877, 7.158862023497898) # Unifr\n",
    "limits = 2000 # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined legend\n",
    "legend_html = '''\n",
    "     <div style=\"position: fixed; \n",
    "                 bottom: 50px; left: 50px; width: 160px; height: 300px; \n",
    "                 background-color: white; border:2px solid grey; z-index:9999; \n",
    "                 font-size:14px;\">\n",
    "     &nbsp; <b>Legend</b> <br>\n",
    "     &nbsp; Walking &nbsp; <i class=\"fa fa-square\" style=\"color:#7FC97F\"></i><br>\n",
    "     &nbsp; On Bicycle &nbsp; <i class=\"fa fa-square\" style=\"color:#BDAED4\"></i><br>\n",
    "     &nbsp; Train &nbsp; <i class=\"fa fa-square\" style=\"color:#FDBF85\"></i><br>\n",
    "     &nbsp; Bus &nbsp; <i class=\"fa fa-square\" style=\"color:#FFFF99\"></i><br>\n",
    "     &nbsp; Electric Bus &nbsp; <i class=\"fa fa-square\" style=\"color:#FFFF99\"></i><br>\n",
    "     &nbsp; Car &nbsp; <i class=\"fa fa-square\" style=\"color:#386CB0\"></i><br>\n",
    "     &nbsp; Tram &nbsp; <i class=\"fa fa-square\" style=\"color:#F0027F\"></i><br>\n",
    "     &nbsp; Plane &nbsp; <i class=\"fa fa-square\" style=\"color:#BE5B17\"></i><br>\n",
    "     &nbsp; Boat &nbsp; <i class=\"fa fa-square\" style=\"color:#BE5B17\"></i><br>\n",
    "      </div>\n",
    "     '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file('data/path.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns with coordinates (latitude, longitude and accuracy)\n",
    "df = df[['moveId', 'latitude', 'longitude', 'accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moveId</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.7938337</td>\n",
       "      <td>7.1589473</td>\n",
       "      <td>15.12600040435791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>46.7945523</td>\n",
       "      <td>7.1573563</td>\n",
       "      <td>22.886999130249023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46.7952677</td>\n",
       "      <td>7.1565532</td>\n",
       "      <td>46.82500076293945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>46.7963267</td>\n",
       "      <td>7.1553883</td>\n",
       "      <td>17.33099937438965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>46.7968228</td>\n",
       "      <td>7.1547272</td>\n",
       "      <td>10.956999778747559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>425</td>\n",
       "      <td>46.7929895</td>\n",
       "      <td>7.1551063</td>\n",
       "      <td>72.9000015258789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>426</td>\n",
       "      <td>46.7929658</td>\n",
       "      <td>7.1549381</td>\n",
       "      <td>32.887001037597656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>427</td>\n",
       "      <td>46.7946359</td>\n",
       "      <td>7.1550851</td>\n",
       "      <td>18.374000549316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>428</td>\n",
       "      <td>46.7943201</td>\n",
       "      <td>7.1550194</td>\n",
       "      <td>17.253000259399414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>428</td>\n",
       "      <td>46.7939358</td>\n",
       "      <td>7.1586261</td>\n",
       "      <td>25.979999542236328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3216 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     moveId    latitude  longitude            accuracy\n",
       "0         0  46.7938337  7.1589473   15.12600040435791\n",
       "1         1  46.7945523  7.1573563  22.886999130249023\n",
       "2         1  46.7952677  7.1565532   46.82500076293945\n",
       "3         1  46.7963267  7.1553883   17.33099937438965\n",
       "4         1  46.7968228  7.1547272  10.956999778747559\n",
       "...     ...         ...        ...                 ...\n",
       "3211    425  46.7929895  7.1551063    72.9000015258789\n",
       "3212    426  46.7929658  7.1549381  32.887001037597656\n",
       "3213    427  46.7946359  7.1550851  18.374000549316406\n",
       "3214    428  46.7943201  7.1550194  17.253000259399414\n",
       "3215    428  46.7939358  7.1586261  25.979999542236328\n",
       "\n",
       "[3216 rows x 4 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance point-point (in meters)\n",
    "def dist(p1, p2):\n",
    "    return geopy.distance.geodesic(p1, p2).m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert locations to geohashes with varying precision, depending on their distance from the center\n",
    "def geohash(lat, lon):\n",
    "    p = (lat, lon)\n",
    "    d = dist(center, p)\n",
    "    if d < limits//2:\n",
    "        return geolib.encode(lat, lon, precision=8) #8\n",
    "    elif d < limits:\n",
    "        return geolib.encode(lat, lon, precision=8) #7\n",
    "    else:\n",
    "        return geolib.encode(lat, lon, precision=8) #6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with geohash\n",
    "df['geohash'] = df.apply(lambda x: geohash(x['latitude'], x['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moveId</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>geohash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.7938337</td>\n",
       "      <td>7.1589473</td>\n",
       "      <td>15.12600040435791</td>\n",
       "      <td>u0m44ysc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>46.7945523</td>\n",
       "      <td>7.1573563</td>\n",
       "      <td>22.886999130249023</td>\n",
       "      <td>u0m44yey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46.7952677</td>\n",
       "      <td>7.1565532</td>\n",
       "      <td>46.82500076293945</td>\n",
       "      <td>u0m44yg4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>46.7963267</td>\n",
       "      <td>7.1553883</td>\n",
       "      <td>17.33099937438965</td>\n",
       "      <td>u0m44z42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>46.7958022</td>\n",
       "      <td>7.1559085</td>\n",
       "      <td>11.0</td>\n",
       "      <td>u0m44yfv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>425</td>\n",
       "      <td>46.7929895</td>\n",
       "      <td>7.1551063</td>\n",
       "      <td>72.9000015258789</td>\n",
       "      <td>u0m44y6h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>426</td>\n",
       "      <td>46.7929658</td>\n",
       "      <td>7.1549381</td>\n",
       "      <td>32.887001037597656</td>\n",
       "      <td>u0m44y6h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>427</td>\n",
       "      <td>46.7946359</td>\n",
       "      <td>7.1550851</td>\n",
       "      <td>18.374000549316406</td>\n",
       "      <td>u0m44ydn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>428</td>\n",
       "      <td>46.7943201</td>\n",
       "      <td>7.1550194</td>\n",
       "      <td>17.253000259399414</td>\n",
       "      <td>u0m44ydh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>428</td>\n",
       "      <td>46.7939358</td>\n",
       "      <td>7.1586261</td>\n",
       "      <td>25.979999542236328</td>\n",
       "      <td>u0m44ysf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     moveId    latitude  longitude            accuracy   geohash\n",
       "0         0  46.7938337  7.1589473   15.12600040435791  u0m44ysc\n",
       "1         1  46.7945523  7.1573563  22.886999130249023  u0m44yey\n",
       "2         1  46.7952677  7.1565532   46.82500076293945  u0m44yg4\n",
       "3         1  46.7963267  7.1553883   17.33099937438965  u0m44z42\n",
       "7         3  46.7958022  7.1559085                11.0  u0m44yfv\n",
       "...     ...         ...        ...                 ...       ...\n",
       "3211    425  46.7929895  7.1551063    72.9000015258789  u0m44y6h\n",
       "3212    426  46.7929658  7.1549381  32.887001037597656  u0m44y6h\n",
       "3213    427  46.7946359  7.1550851  18.374000549316406  u0m44ydn\n",
       "3214    428  46.7943201  7.1550194  17.253000259399414  u0m44ydh\n",
       "3215    428  46.7939358  7.1586261  25.979999542236328  u0m44ysf\n",
       "\n",
       "[2143 rows x 5 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points, removing the ones in the proximity of start and end locations, if they are not in the same area as the POI.\n",
    "def filter_points(df_in):\n",
    "    rows_list = []\n",
    "    # Start and end locations per each moveId\n",
    "    start_end = df_in.groupby('moveId').agg({'latitude': ['first', 'last'], 'longitude': ['first', 'last']})\n",
    "\n",
    "    for index, row in df_in.iterrows():\n",
    "        moveId = row['moveId']\n",
    "        p = (row['latitude'], row['longitude'])\n",
    "        p_start = (start_end.loc[moveId, ('latitude', 'first')], start_end.loc[moveId, ('longitude', 'first')])\n",
    "        p_end = (start_end.loc[moveId, ('latitude', 'last')], start_end.loc[moveId, ('longitude', 'last')])\n",
    "\n",
    "        if (dist(p, p_start) > limits/5 and dist(p, p_end) > limits/5) or dist(center,p) < limits/5:\n",
    "            rows_list.append(row)\n",
    "    return pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the count of points per geohash\n",
    "df_filtered = filter_points(df)\n",
    "df_filtered = df_filtered.groupby('geohash').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a visualization of the covered routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a coordinate from a geohash, adding a small random offset to avoid overlapping\n",
    "def geohash_to_coordinate(geohash):\n",
    "    lat, lon = geolib.decode(geohash)\n",
    "    #lat = float(lat) + 0.00000001#(random.random() - 0.5) * 0.00000001\n",
    "    #lon = float(lon) + 0.00000001#(random.random() - 0.5) * 0.00000001\n",
    "    return [float(lat), float(lon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draw a path from start_geohash to end_geohash on a folium map\n",
    "def draw_path(start_geohash, end_geohash, mean_of_transport, map, weight=1, tooltip=None):\n",
    "    ## Give a different color to each mean of transport\n",
    "    colors = {\n",
    "        'WALKING': '#7FC97F',\n",
    "        'ON_BICYCLE': '#BDAED4',\n",
    "        'ELECTRIC_BIKE': '#BDAED4',\n",
    "        'SCOOTER': '#BDAED4',\n",
    "        'TRAIN': '#FDBF85',\n",
    "        'BUS': '#FFFF99',\n",
    "        'ELECTRIC_BUS': '#FFFF99',\n",
    "        'CAR': '#386CB0',\n",
    "        'ELECTRIC_CAR': '#386CB0',\n",
    "        'TRAM': '#F0027F',\n",
    "        'PLANE': '#BE5B17',\n",
    "        'BOAT': '#BE5B17',\n",
    "        'DETECTION_ERROR': '#000000'\n",
    "    }\n",
    "    start_coord = geohash_to_coordinate(start_geohash)\n",
    "    end_coord = geohash_to_coordinate(end_geohash)\n",
    "\n",
    "    # Add a small offset to avoid overlapping\n",
    "    start_coord[0] += (random.random() - 0.5) * 0.001\n",
    "    start_coord[1] += (random.random() - 0.5) * 0.001\n",
    "    end_coord[0] += (random.random() - 0.5) * 0.001\n",
    "    end_coord[1] += (random.random() - 0.5) * 0.001\n",
    "\n",
    "    #arc_drawer.draw_arc(map, start_coord[0], start_coord[1], end_coord[0], end_coord[1], color=colors[mean_of_transport], weight = weight)\n",
    "\n",
    "    folium.PolyLine(locations=[start_coord, end_coord], color=colors[mean_of_transport], weight=weight, tooltip=tooltip).add_to(map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a heatmap of the locations visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_points(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1811"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract from df a list of all start_geohashes and end_geohashes\n",
    "geohashes = list(df['geohash'])\n",
    "len(geohashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of geohashes to a dataframe\n",
    "geohashes_df = gpd.GeoDataFrame(geohashes, columns=['geohash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode geohashes to latitude and longitude\n",
    "df_filtered['latitude'] = df_filtered['geohash'].apply(lambda x: geohash_to_coordinate(x)[0])\n",
    "df_filtered['longitude'] = df_filtered['geohash'].apply(lambda x: geohash_to_coordinate(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "m = folium.Map(location=[df_filtered['latitude'].mean(), df_filtered['longitude'].mean()], zoom_start=10)\n",
    "\n",
    "# Prepare data for the heatmap\n",
    "heat_data = [[row['latitude'], row['longitude'], row['count']] for index, row in df_filtered.iterrows()]\n",
    "\n",
    "# Create a heatmap layer\n",
    "HeatMap(heat_data).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m.save('maps/fine_heatmap.html')\n",
    "!open -a Arc maps/fine_heatmap.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the list of geohashes to a geoJSON object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â Convert geohashes to a heatmap in geojson format\n",
    "def geohashes_to_heatmap(df):\n",
    "    # Get the distinct geohashes and their counts from the dataframe\n",
    "    geohashes = df['geohash'].value_counts()\n",
    "\n",
    "    # Get the maximum count of any geohash\n",
    "    max_count = math.log(geohashes.max())\n",
    "\n",
    "    # Convert the geohashes to a list of lists, each containing the geohash and its count\n",
    "    geohashes = [[geohash, count] for geohash, count in zip(geohashes.index, geohashes)]\n",
    "    \n",
    "    # Create a color scale for the heatmap\n",
    "    color_scale = linear.RdYlBu_10.scale(1, max_count)\n",
    "\n",
    "    # Convert geohashes to features for geoJSON\n",
    "    features = []\n",
    "\n",
    "    for geohash in geohashes:\n",
    "        # Get the bounds of the geohash\n",
    "        bounds = geolib.bounds(geohash[0])\n",
    "        color = color_scale(math.log(geohash[1]))\n",
    "\n",
    "        # Create a feature for the geohash\n",
    "        features.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"id\": geohash[0],\n",
    "                \"fillColor\": color,\n",
    "                \"fillOpacity\": 0.6,\n",
    "                \"stroke\": False\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Polygon\",\n",
    "                \"coordinates\": [[\n",
    "                    [bounds.sw.lon, bounds.sw.lat],\n",
    "                    [bounds.sw.lon, bounds.ne.lat],\n",
    "                    [bounds.ne.lon, bounds.ne.lat],\n",
    "                    [bounds.ne.lon, bounds.sw.lat],\n",
    "                    [bounds.sw.lon, bounds.sw.lat]\n",
    "                ]]\n",
    "            },\n",
    "        })\n",
    "\n",
    "    # Convert the geohashes to a heatmap in geojson format\n",
    "    return {\n",
    "        \"type\" : \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the geohashes to a heatmap in geojson format\n",
    "heatmap = geohashes_to_heatmap(geohashes_df)\n",
    "\n",
    "# Save GeoJSON with double quotes\n",
    "with open('results/heatmap.geojson', 'w') as f:\n",
    "    json.dump(heatmap, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as a heatmap using Folium\n",
    "# Create a folium map centered at an initial location\n",
    "def create_map(geojson, mapname, legend=None):\n",
    "    m = folium.Map(location=[46.9446011, 7.4143311],zoom_start=10, tiles='https://tiles.stadiamaps.com/tiles/stamen_toner_lite/{z}/{x}/{y}{r}.png?api_key=977802c5-9b2e-4fc3-9254-a9199d0d5d0c', attr='https://stadiamaps.com/')\n",
    "\n",
    "    # Define a style function to set the color of the polygon\n",
    "    def style_function(feature):\n",
    "        return {\n",
    "            'fillColor': feature[\"properties\"][\"fillColor\"],  # Change this to the desired color\n",
    "            'stroke': feature[\"properties\"][\"stroke\"],\n",
    "            'fillOpacity': feature[\"properties\"][\"fillOpacity\"],\n",
    "        }\n",
    "\n",
    "    # Add GeoJSON data to the map with the style function\n",
    "    folium.GeoJson(\n",
    "        geojson,\n",
    "        name='Polygon Layer',\n",
    "        style_function=style_function,\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add Layer Control to the map\n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "    if legend:\n",
    "        m.get_root().html.add_child(folium.Element(legend))\n",
    "\n",
    "    # Save or display the map\n",
    "    m.save(\"maps/\"+mapname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_map(heatmap, \"heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open -a Arc maps/heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw on map points with lat and long of the path coordinates\n",
    "m = folium.Map(location=[46.9446011, 7.4143311], zoom_start=10, tiles='https://tiles.stadiamaps.com/tiles/stamen_toner_lite/{z}/{x}/{y}{r}.png?api_key=977802c5-9b2e-4fc3-9254-a9199d0d5d0c', attr='https://stadiamaps.com/')\n",
    "for i, row in df.iterrows():\n",
    "    folium.CircleMarker(location=[row['latitude'], row['longitude']], radius=1, color='blue').add_to(m)\n",
    "\n",
    "m.save('maps/points.html')\n",
    "!open -a Arc maps/points.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the map of the most used vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['start_geohash', 'mean_of_transport'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Get the list of geohashes with the corresponding mean of transport\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m geohashes \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_geohash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_of_transport\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Append the end_geohashes to the list of geohashes\u001b[39;00m\n\u001b[1;32m      4\u001b[0m geohashes \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(pd\u001b[38;5;241m.\u001b[39mconcat([geohashes, df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_geohash\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_of_transport\u001b[39m\u001b[38;5;124m'\u001b[39m]]]))\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['start_geohash', 'mean_of_transport'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "## Get the list of geohashes with the corresponding mean of transport\n",
    "geohashes = df[['start_geohash', 'mean_of_transport']].copy()\n",
    "## Append the end_geohashes to the list of geohashes\n",
    "geohashes = gpd.GeoDataFrame(pd.concat([geohashes, df[['end_geohash', 'mean_of_transport']]]))\n",
    "## Merge start_geohashes and end_geohashes into a single column\n",
    "geohashes['geohash'] = geohashes['start_geohash'].combine_first(geohashes['end_geohash'])\n",
    "## Remove the start_geohashes and end_geohashes columns\n",
    "geohashes = geohashes[['geohash', 'mean_of_transport']]\n",
    "\n",
    "## Reduce precision of geohashes\n",
    "geohashes['geohash'] = geohashes['geohash'] #.str[:-1]\n",
    "\n",
    "geohashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geohash</th>\n",
       "      <th>mean_of_transport</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>u0m44x</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>u0m468</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>u0m714</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>u0m470</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>u0m46b</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>u0nq9p</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>u0nq9r</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>u0nq9w</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>u0nqc0</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>u0nqsy</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    geohash mean_of_transport  counts\n",
       "60   u0m44x           WALKING      47\n",
       "74   u0m468             TRAIN      21\n",
       "132  u0m714             TRAIN      19\n",
       "86   u0m470           WALKING      17\n",
       "80   u0m46b           WALKING      17\n",
       "..      ...               ...     ...\n",
       "214  u0nq9p               CAR       1\n",
       "215  u0nq9r               CAR       1\n",
       "216  u0nq9w               CAR       1\n",
       "219  u0nqc0               CAR       1\n",
       "220  u0nqsy               CAR       1\n",
       "\n",
       "[161 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find the mean of transport that occurs the more often for each geohash and keep only the first one (the most used)\n",
    "geohashes_df = gpd.GeoDataFrame(geohashes, columns=['geohash', 'mean_of_transport'])\n",
    "# Get the count of the mean of transport for each geohash\n",
    "geohashes_df = geohashes_df.groupby(['geohash', 'mean_of_transport']).size().reset_index(name='counts')\n",
    "# For each geohash, keep only the mean of transport that occurs the most often\n",
    "geohashes_df = geohashes_df.sort_values('counts', ascending=False).drop_duplicates(['geohash'])\n",
    "# Remove the counts column\n",
    "#geohashes_df = geohashes_df[['geohash', 'mean_of_transport']]\n",
    "geohashes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert geohashes to a heatmap in geojson format\n",
    "def heatmap_mot(df):\n",
    "    ## Give a different color to each mean of transport\n",
    "    colors = {\n",
    "        'WALKING': '#7FC97F',\n",
    "        'ON_BICYCLE': '#BDAED4',\n",
    "        'ELECTRIC_BIKE': '#BDAED4',\n",
    "        'SCOOTER': '#BDAED4',\n",
    "        'TRAIN': '#FDBF85',\n",
    "        'BUS': '#FFFF99',\n",
    "        'ELECTRIC_BUS': '#FFFF99',\n",
    "        'CAR': '#386CB0',\n",
    "        'ELECTRIC_CAR': '#386CB0',\n",
    "        'TRAM': '#F0027F',\n",
    "        'PLANE': '#BE5B17',\n",
    "        'BOAT': '#BE5B17'\n",
    "    }\n",
    "\n",
    "    # Convert geohashes to features for geoJSON\n",
    "    features = []\n",
    "\n",
    "    for geohash in df:\n",
    "        # Get the bounds of the geohash\n",
    "        bounds = geolib.bounds(geohash[0])\n",
    "        color = colors[geohash[1]]\n",
    "\n",
    "        # Create a feature for the geohash\n",
    "        features.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"id\": geohash[0],\n",
    "                \"fillColor\": color,\n",
    "                \"fillOpacity\": 0.8,\n",
    "                \"stroke\": False\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Polygon\",\n",
    "                \"coordinates\": [[\n",
    "                    [bounds.sw.lon, bounds.sw.lat],\n",
    "                    [bounds.sw.lon, bounds.ne.lat],\n",
    "                    [bounds.ne.lon, bounds.ne.lat],\n",
    "                    [bounds.ne.lon, bounds.sw.lat],\n",
    "                    [bounds.sw.lon, bounds.sw.lat]\n",
    "                ]]\n",
    "            },\n",
    "        })\n",
    "\n",
    "    # Convert the geohashes to a heatmap in geojson format\n",
    "    return {\n",
    "        \"type\" : \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'heatmap_mot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the means of transport to a heatmap in geojson format\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mheatmap_mot\u001b[49m(geohashes_df\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save GeoJSON with double quotes\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/heatmap_mot.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'heatmap_mot' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert the means of transport to a heatmap in geojson format\n",
    "heatmap = heatmap_mot(geohashes_df.values)\n",
    "\n",
    "# Save GeoJSON with double quotes\n",
    "with open('results/heatmap_mot.geojson', 'w') as f:\n",
    "    json.dump(heatmap, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_map(heatmap, \"heatmap_mot.html\", legend_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open -a Arc maps/heatmap_mot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the map of the movements (start to end point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'start_geohash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_geohash'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Draw a path for each movement\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 8\u001b[0m     draw_path(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_geohash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_geohash\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_of_transport\u001b[39m\u001b[38;5;124m'\u001b[39m], m, weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, tooltip\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticipant_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m## Add the legend to the map\u001b[39;00m\n\u001b[1;32m     12\u001b[0m m\u001b[38;5;241m.\u001b[39mget_root()\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39madd_child(folium\u001b[38;5;241m.\u001b[39mElement(legend_html))\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Documents/Lavoro/SWICE/Software/tests/OSMnx/osmnx/lib/python3.9/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_geohash'"
     ]
    }
   ],
   "source": [
    "# Now we should create a map with lines between the geohashes, with the color of the line corresponding to the mean of transport\n",
    "# We should also create a legend for the map\n",
    "\n",
    "## Create the actual folium map\n",
    "m = folium.Map(location=[46.9446011, 7.4143311], zoom_start=8, tiles='https://tiles.stadiamaps.com/tiles/stamen_toner_lite/{z}/{x}/{y}{r}.png?api_key=977802c5-9b2e-4fc3-9254-a9199d0d5d0c', attr='https://stadiamaps.com/')\n",
    "# Draw a path for each movement\n",
    "for index, row in df.iterrows():\n",
    "    draw_path(row['start_geohash'], row['end_geohash'], row['mean_of_transport'], m, weight = 2, tooltip=row['participant_id'])\n",
    "\n",
    "\n",
    "## Add the legend to the map\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "## Save the map as an html file\n",
    "m.save('maps/paths_map_mot.html')\n",
    "\n",
    "!open -a Arc maps/paths_map_mot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osmnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
